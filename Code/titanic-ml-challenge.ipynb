{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "train_csv_path = r'C:\\Users\\TDInstaller\\Documents\\Kaggle\\titanic\\train.csv'\n",
    "test_csv_path = r'C:\\Users\\TDInstaller\\Documents\\Kaggle\\titanic\\test.csv'\n",
    "raw_data_train = pd.read_csv(train_csv_path)\n",
    "raw_data_test = pd.read_csv(test_csv_path)\n",
    "\n",
    "titanic_data_train = raw_data_train.copy()\n",
    "titanic_data_test = raw_data_test.copy()\n",
    "titanic_data_train ['Source_File'] = 'Train'\n",
    "titanic_data_test ['Source_File'] = 'Test'\n",
    "titanic_data = pd.concat([titanic_data_train,titanic_data_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data_copy = titanic_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Source Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.describe() #for numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Seems like ~38.4% of passengers survived\n",
    "* Most of the passengers were in 3rd class\n",
    "* Average age is ~30 years\n",
    "* SibSp/Parch seems to be mostly zeros i.e. most passengers were travelling alone\n",
    "* Fare values are higly varied (high variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Variables Vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex Vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=titanic_data, x='Sex', y='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data, x='Sex', hue='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data=titanic_data, columns='Sex', index='Survived', values= 'PassengerId' ,aggfunc='count', margins=True)\n",
    "#male passengers were more than female ones, but more females survived than males (women and children first) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data[['Survived','Sex']].groupby('Sex').mean().sort_values(by='Survived', ascending=False)['Survived']*100\n",
    "#order by survived so 1= Survived will represent the first row\n",
    "#~74% of females survived\n",
    "#~19% of males survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = titanic_data[['PassengerId','Sex']].groupby('Sex').count().reset_index()\n",
    "t['%'] = t['PassengerId']/len(titanic_data)*100\n",
    "t\n",
    "#~64% of passengers were males"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embarked Vs Survival "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=titanic_data, x='Embarked', y='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data, x='Embarked', hue='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data=titanic_data, columns='Embarked', index='Survived', values= 'PassengerId' ,aggfunc='count', margins=True )\n",
    "#most pple who survived had departed from South Hampton, but most passengers actually departed from there anyway, \n",
    "#and actually, majority of pple who departed from South Hampton didn't survive\n",
    "#people who departed from Cherbourg are more likely to survive than not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like C are more likely to survive indeed\n",
    "titanic_data[[\"Embarked\", \"Survived\"]].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cabin, Pclass Vs Survival "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['cabin_cat_series'] = titanic_data['Cabin'].apply(lambda x:str(x)[0])\n",
    "pd.pivot_table(data=titanic_data, columns='cabin_cat_series', index='Survived', values= 'PassengerId' ,aggfunc='count', margins=True )\n",
    "#most pple have unknown cabins 687/891 passengers\n",
    "#most unknown cabiners didn't survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.groupby(['cabin_cat_series','Pclass'])['PassengerId'].count()\n",
    "#majority of unknown cabins are in class 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data=titanic_data, columns='Pclass', index='Survived', values= 'PassengerId' ,aggfunc='count', margins=True )\n",
    "# majority of class 3 sdidn't survive \n",
    "# conc seems like most unknown cabiners didn't survice, most of the unknowns were class 3, and majority of class 3 didn't survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['cabin_unknown']=titanic_data['cabin_cat_series'].apply(lambda x: 1 if x =='n' else 0)\n",
    "sns.countplot(data=titanic_data ,x='cabin_unknown') #most passengers have unknown cabins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data ,x='cabin_unknown', hue='Survived') #unknown cabiners are less likely to survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data ,x='Pclass') #most passengers are 3rd class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data ,x='Pclass', hue='Survived') #first class are more likely to survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data ,x='cabin_unknown', hue='Pclass') #unkown cabiners are more likely to be 3rd class which is least likely to survive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SibSp Vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data=titanic_data, columns='SibSp', index='Survived', values= 'PassengerId' ,aggfunc='count', margins=True )\n",
    "#most passengers had 0 or 1 SibSP (already deduced before that most passengers travelled alone)\n",
    "#people with 0 or 1 siblings and spouses had higher chance of survival compared to pple with more sib/sps. \n",
    "#However, we can also see that only 210/608 pple who traveled alone survived\n",
    "#looks like majority of passengers traveled alone and majority of passegers didn't survive,which are two things we already know\n",
    "#but overall if a passenger is travelling alone, they would have higher chance to survive than otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data, x='SibSp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data, x='SibSp', hue='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=titanic_data, x='SibSp', y='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parch Vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data=titanic_data, columns='Parch', index='Survived', values= 'PassengerId' ,aggfunc='count', margins=True )\n",
    "#looks like travelling with 0 or 1 parets/children gives you a higher chance of survival than otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data, x='Parch', hue='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=titanic_data, x='Parch', y='Survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket Vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(titanic_data.Ticket.unique()) #some tickets are numeric and some are alphanumeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.Ticket.nunique()/titanic_data.Ticket.shape[0]*100\n",
    "#~71% of tickets are unique, so  may be some tickets have multiple passangers on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['numeric_Ticket'] = titanic_data['Ticket'].apply(lambda x:1 if x.isnumeric() else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(data=titanic_data, columns='numeric_Ticket', index='Survived', values= 'PassengerId' ,aggfunc='count', margins=True )\n",
    "#majority of tickets were numeric, majority representation makes it so that majority of survivals had numeric tickets \n",
    "#and majority of those whose didn't survive are also holders of numeric tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data, x='numeric_Ticket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data, x='numeric_Ticket', hue='Survived') # doesn't seem like eother type would inc likelihood of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=titanic_data, x='numeric_Ticket', y='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data, x='numeric_Ticket', hue='Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age, class Vs survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,1, figsize = (16, 5))\n",
    "sns.distplot(titanic_data.Age);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=titanic_data, x='Pclass', y='Age') #3rd class are the youngest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(titanic_data, col='Pclass')\n",
    "g.map(plt.hist, 'Age', bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(titanic_data, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the ages into age groups #explore more about binning!\n",
    "bins = [0, 2, 12, 17, 60, np.inf]\n",
    "labels = ['baby', 'child', 'teenager', 'adult', 'elderly']\n",
    "age_groups = pd.cut(titanic_data.Age, bins, labels = labels)\n",
    "titanic_data['Age_Group'] = age_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data, x='Age_Group',hue='Survived') #babies and children are more likely to survive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=titanic_data, x='Age_Group',hue='Pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=titanic_data,x=\"Age_Group\", y=\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare vs Survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,1, figsize = (16, 5))\n",
    "sns.distplot(titanic_data.Fare);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(titanic_data.Fare);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_fares = titanic_data[titanic_data['Survived']==1][['Fare','Survived']]\n",
    "not_survived_fares = titanic_data[titanic_data['Survived']==0][['Fare','Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 4))\n",
    "sns.distplot(survived_fares.Fare);\n",
    "sns.distplot(not_survived_fares.Fare);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (16, 4))\n",
    "sns.distplot(survived_fares.Fare, label='Survived=1');\n",
    "sns.distplot(not_survived_fares.Fare, label='Survived=0');\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,1, figsize = (14, 3))\n",
    "sns.distplot(survived_fares.Fare).set_title('Fares Dist For Survivors');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,1, figsize = (14, 3))\n",
    "sns.distplot(not_survived_fares.Fare).set_title('Fares Dist For Non-Survivors');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher fare correlates with higher survival rate\n",
    "g = sns.FacetGrid(titanic_data, col='Survived')\n",
    "g.map(plt.hist, 'Fare', bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data = titanic_data_copy.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_avgAge():\n",
    "    return titanic_data.groupby('Pclass')['Age'].mean()\n",
    "\n",
    "def derive_age(cols):\n",
    "    Age = cols[0]\n",
    "    Pclass = cols[1]\n",
    "    if pd.isnull(Age):\n",
    "        return get_class_avgAge()[Pclass]\n",
    "    else:\n",
    "        return Age\n",
    "\n",
    "titanic_data['Age'] = titanic_data[['Age','Pclass']].apply(derive_age,axis=1)  \n",
    "\n",
    "bins = [0, 2, 12, 17, 60, np.inf]\n",
    "labels = ['baby', 'child', 'teenager', 'adult', 'elderly']\n",
    "age_groups = pd.cut(titanic_data.Age, bins, labels = labels)\n",
    "titanic_data['Age_Group'] = age_groups\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title, Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "titanic_data['passenger_title'] = titanic_data.Name.apply(lambda x: x.split(',',1)[1].split('.')[0].strip()).values\n",
    "\n",
    "titanic_data['cabin_cat'] = titanic_data.Cabin.apply(lambda x: str(x)[0])\n",
    "titanic_data['cabin_multiple'] = titanic_data.Cabin.apply(lambda x: 0 if pd.isna(x) else len(x.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data['numeric_ticket'] = titanic_data.Ticket.apply(lambda x: 1 if x.isnumeric() else 0)\n",
    "titanic_data['Ticket_Frequency'] = titanic_data.groupby('Ticket')['PassengerId'].count()\n",
    "\n",
    "def get_all_tickets_frequency():\n",
    "        return titanic_data.groupby('Ticket')['PassengerId'].count()\n",
    "def get_single_ticket_frequency(cols):\n",
    "    Ticket = cols[0]\n",
    "    return get_all_tickets_frequency()[str(Ticket)]   \n",
    "titanic_data['Ticket_Frequency'] = titanic_data[['Ticket']].apply(get_single_ticket_frequency,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_avgFare():\n",
    "    return titanic_data.groupby('Pclass')['Fare'].mean()\n",
    "    \n",
    "def derive_Fare(cols):\n",
    "    Fare = cols[0]\n",
    "    Pclass = cols[1]\n",
    "    if pd.isnull(Fare):\n",
    "        return get_class_avgFare()[Pclass]\n",
    "    else:\n",
    "        return Fare   \n",
    "    \n",
    "titanic_data['Fare'] = titanic_data[['Fare','Pclass']].apply(derive_Fare,axis=1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final na handeling and data types handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1309 entries, 0 to 417\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   PassengerId       1309 non-null   int64   \n",
      " 1   Survived          891 non-null    float64 \n",
      " 2   Pclass            1309 non-null   int64   \n",
      " 3   Name              1309 non-null   object  \n",
      " 4   Sex               1309 non-null   object  \n",
      " 5   Age               1309 non-null   float64 \n",
      " 6   SibSp             1309 non-null   int64   \n",
      " 7   Parch             1309 non-null   int64   \n",
      " 8   Ticket            1309 non-null   object  \n",
      " 9   Fare              1309 non-null   float64 \n",
      " 10  Cabin             295 non-null    object  \n",
      " 11  Embarked          1307 non-null   object  \n",
      " 12  Source_File       1309 non-null   object  \n",
      " 13  Age_Group         1309 non-null   category\n",
      " 14  passenger_title   1309 non-null   object  \n",
      " 15  cabin_cat         1309 non-null   object  \n",
      " 16  cabin_multiple    1309 non-null   int64   \n",
      " 17  numeric_ticket    1309 non-null   int64   \n",
      " 18  Ticket_Frequency  1309 non-null   int64   \n",
      "dtypes: category(1), float64(3), int64(7), object(8)\n",
      "memory usage: 195.8+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_data.dropna(subset=['Embarked'],inplace = True)\n",
    "titanic_data.Pclass = titanic_data.Pclass.astype(str)\n",
    "titanic_data.numeric_ticket = titanic_data.numeric_ticket.astype(str)\n",
    "titanic_data['Age'] = round(titanic_data['Age'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1307 entries, 0 to 417\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype   \n",
      "---  ------            --------------  -----   \n",
      " 0   PassengerId       1307 non-null   int64   \n",
      " 1   Survived          889 non-null    float64 \n",
      " 2   Pclass            1307 non-null   object  \n",
      " 3   Name              1307 non-null   object  \n",
      " 4   Sex               1307 non-null   object  \n",
      " 5   Age               1307 non-null   float64 \n",
      " 6   SibSp             1307 non-null   int64   \n",
      " 7   Parch             1307 non-null   int64   \n",
      " 8   Ticket            1307 non-null   object  \n",
      " 9   Fare              1307 non-null   float64 \n",
      " 10  Cabin             293 non-null    object  \n",
      " 11  Embarked          1307 non-null   object  \n",
      " 12  Source_File       1307 non-null   object  \n",
      " 13  Age_Group         1307 non-null   category\n",
      " 14  passenger_title   1307 non-null   object  \n",
      " 15  cabin_cat         1307 non-null   object  \n",
      " 16  cabin_multiple    1307 non-null   int64   \n",
      " 17  numeric_ticket    1307 non-null   object  \n",
      " 18  Ticket_Frequency  1307 non-null   int64   \n",
      "dtypes: category(1), float64(3), int64(5), object(10)\n",
      "memory usage: 195.5+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added age groups instead of age\n",
    "all_dummies = pd.get_dummies(titanic_data[['Pclass','Sex','Age_Group','SibSp','Fare','Parch','Embarked','Ticket_Frequency','cabin_cat','cabin_multiple','numeric_ticket','passenger_title','Source_File']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SibSp', 'Fare', 'Parch', 'Ticket_Frequency', 'cabin_multiple',\n",
       "       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Sex_female', 'Sex_male',\n",
       "       'Age_Group_baby', 'Age_Group_child', 'Age_Group_teenager',\n",
       "       'Age_Group_adult', 'Age_Group_elderly', 'Embarked_C', 'Embarked_Q',\n",
       "       'Embarked_S', 'cabin_cat_A', 'cabin_cat_B', 'cabin_cat_C',\n",
       "       'cabin_cat_D', 'cabin_cat_E', 'cabin_cat_F', 'cabin_cat_G',\n",
       "       'cabin_cat_T', 'cabin_cat_n', 'numeric_ticket_0', 'numeric_ticket_1',\n",
       "       'passenger_title_Capt', 'passenger_title_Col', 'passenger_title_Don',\n",
       "       'passenger_title_Dona', 'passenger_title_Dr',\n",
       "       'passenger_title_Jonkheer', 'passenger_title_Lady',\n",
       "       'passenger_title_Major', 'passenger_title_Master',\n",
       "       'passenger_title_Miss', 'passenger_title_Mlle', 'passenger_title_Mme',\n",
       "       'passenger_title_Mr', 'passenger_title_Mrs', 'passenger_title_Ms',\n",
       "       'passenger_title_Rev', 'passenger_title_Sir',\n",
       "       'passenger_title_the Countess', 'Source_File_Test',\n",
       "       'Source_File_Train'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dummies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Splitting train_csv from Test_csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = all_dummies[all_dummies.Source_File_Train == 1].drop(['Source_File_Train','Source_File_Test'], axis =1)\n",
    "y_train_data = titanic_data['Survived'].dropna()\n",
    "\n",
    "train_csv = pd.concat([X_train_data,y_train_data], axis=1)\n",
    "\n",
    "X_test = all_dummies[all_dummies.Source_File_Train == 0].drop(['Source_File_Train','Source_File_Test'], axis =1)\n",
    "test_csv = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket_Frequency</th>\n",
       "      <th>cabin_multiple</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>passenger_title_Miss</th>\n",
       "      <th>passenger_title_Mlle</th>\n",
       "      <th>passenger_title_Mme</th>\n",
       "      <th>passenger_title_Mr</th>\n",
       "      <th>passenger_title_Mrs</th>\n",
       "      <th>passenger_title_Ms</th>\n",
       "      <th>passenger_title_Rev</th>\n",
       "      <th>passenger_title_Sir</th>\n",
       "      <th>passenger_title_the Countess</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp     Fare  Parch  Ticket_Frequency  cabin_multiple  Pclass_1  \\\n",
       "0      1   7.2500      0                 1               0         0   \n",
       "1      1  71.2833      0                 2               1         1   \n",
       "2      0   7.9250      0                 1               0         0   \n",
       "3      1  53.1000      0                 2               1         1   \n",
       "4      0   8.0500      0                 1               0         0   \n",
       "\n",
       "   Pclass_2  Pclass_3  Sex_female  Sex_male  ...  passenger_title_Miss  \\\n",
       "0         0         1           0         1  ...                     0   \n",
       "1         0         0           1         0  ...                     0   \n",
       "2         0         1           1         0  ...                     1   \n",
       "3         0         0           1         0  ...                     0   \n",
       "4         0         1           0         1  ...                     0   \n",
       "\n",
       "   passenger_title_Mlle  passenger_title_Mme  passenger_title_Mr  \\\n",
       "0                     0                    0                   1   \n",
       "1                     0                    0                   0   \n",
       "2                     0                    0                   0   \n",
       "3                     0                    0                   0   \n",
       "4                     0                    0                   1   \n",
       "\n",
       "   passenger_title_Mrs  passenger_title_Ms  passenger_title_Rev  \\\n",
       "0                    0                   0                    0   \n",
       "1                    1                   0                    0   \n",
       "2                    0                   0                    0   \n",
       "3                    1                   0                    0   \n",
       "4                    0                   0                    0   \n",
       "\n",
       "   passenger_title_Sir  passenger_title_the Countess  Survived  \n",
       "0                    0                             0       0.0  \n",
       "1                    0                             0       1.0  \n",
       "2                    0                             0       1.0  \n",
       "3                    0                             0       1.0  \n",
       "4                    0                             0       0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket_Frequency</th>\n",
       "      <th>cabin_multiple</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>...</th>\n",
       "      <th>passenger_title_Miss</th>\n",
       "      <th>passenger_title_Mlle</th>\n",
       "      <th>passenger_title_Mme</th>\n",
       "      <th>passenger_title_Mr</th>\n",
       "      <th>passenger_title_Mrs</th>\n",
       "      <th>passenger_title_Ms</th>\n",
       "      <th>passenger_title_Rev</th>\n",
       "      <th>passenger_title_Sir</th>\n",
       "      <th>passenger_title_the Countess</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.524184</td>\n",
       "      <td>32.096681</td>\n",
       "      <td>0.382452</td>\n",
       "      <td>2.121485</td>\n",
       "      <td>0.265467</td>\n",
       "      <td>0.240720</td>\n",
       "      <td>0.206974</td>\n",
       "      <td>0.552306</td>\n",
       "      <td>0.350956</td>\n",
       "      <td>0.649044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203600</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.581552</td>\n",
       "      <td>0.139483</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.006749</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.382452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.103705</td>\n",
       "      <td>49.697504</td>\n",
       "      <td>0.806761</td>\n",
       "      <td>1.798673</td>\n",
       "      <td>0.546642</td>\n",
       "      <td>0.427761</td>\n",
       "      <td>0.405365</td>\n",
       "      <td>0.497536</td>\n",
       "      <td>0.477538</td>\n",
       "      <td>0.477538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402901</td>\n",
       "      <td>0.047404</td>\n",
       "      <td>0.033539</td>\n",
       "      <td>0.493582</td>\n",
       "      <td>0.346644</td>\n",
       "      <td>0.033539</td>\n",
       "      <td>0.081922</td>\n",
       "      <td>0.033539</td>\n",
       "      <td>0.033539</td>\n",
       "      <td>0.486260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            SibSp        Fare       Parch  Ticket_Frequency  cabin_multiple  \\\n",
       "count  889.000000  889.000000  889.000000        889.000000      889.000000   \n",
       "mean     0.524184   32.096681    0.382452          2.121485        0.265467   \n",
       "std      1.103705   49.697504    0.806761          1.798673        0.546642   \n",
       "min      0.000000    0.000000    0.000000          1.000000        0.000000   \n",
       "25%      0.000000    7.895800    0.000000          1.000000        0.000000   \n",
       "50%      0.000000   14.454200    0.000000          1.000000        0.000000   \n",
       "75%      1.000000   31.000000    0.000000          3.000000        0.000000   \n",
       "max      8.000000  512.329200    6.000000         11.000000        4.000000   \n",
       "\n",
       "         Pclass_1    Pclass_2    Pclass_3  Sex_female    Sex_male  ...  \\\n",
       "count  889.000000  889.000000  889.000000  889.000000  889.000000  ...   \n",
       "mean     0.240720    0.206974    0.552306    0.350956    0.649044  ...   \n",
       "std      0.427761    0.405365    0.497536    0.477538    0.477538  ...   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000  ...   \n",
       "50%      0.000000    0.000000    1.000000    0.000000    1.000000  ...   \n",
       "75%      0.000000    0.000000    1.000000    1.000000    1.000000  ...   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000  ...   \n",
       "\n",
       "       passenger_title_Miss  passenger_title_Mlle  passenger_title_Mme  \\\n",
       "count            889.000000            889.000000           889.000000   \n",
       "mean               0.203600              0.002250             0.001125   \n",
       "std                0.402901              0.047404             0.033539   \n",
       "min                0.000000              0.000000             0.000000   \n",
       "25%                0.000000              0.000000             0.000000   \n",
       "50%                0.000000              0.000000             0.000000   \n",
       "75%                0.000000              0.000000             0.000000   \n",
       "max                1.000000              1.000000             1.000000   \n",
       "\n",
       "       passenger_title_Mr  passenger_title_Mrs  passenger_title_Ms  \\\n",
       "count          889.000000           889.000000          889.000000   \n",
       "mean             0.581552             0.139483            0.001125   \n",
       "std              0.493582             0.346644            0.033539   \n",
       "min              0.000000             0.000000            0.000000   \n",
       "25%              0.000000             0.000000            0.000000   \n",
       "50%              1.000000             0.000000            0.000000   \n",
       "75%              1.000000             0.000000            0.000000   \n",
       "max              1.000000             1.000000            1.000000   \n",
       "\n",
       "       passenger_title_Rev  passenger_title_Sir  passenger_title_the Countess  \\\n",
       "count           889.000000           889.000000                    889.000000   \n",
       "mean              0.006749             0.001125                      0.001125   \n",
       "std               0.081922             0.033539                      0.033539   \n",
       "min               0.000000             0.000000                      0.000000   \n",
       "25%               0.000000             0.000000                      0.000000   \n",
       "50%               0.000000             0.000000                      0.000000   \n",
       "75%               0.000000             0.000000                      0.000000   \n",
       "max               1.000000             1.000000                      1.000000   \n",
       "\n",
       "         Survived  \n",
       "count  889.000000  \n",
       "mean     0.382452  \n",
       "std      0.486260  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      1.000000  \n",
       "max      1.000000  \n",
       "\n",
       "[8 rows x 48 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scale = StandardScaler()\n",
    "train_inputs = X_train_data.copy()\n",
    "#train_inputs[['Age','SibSp','Parch','Fare','cabin_multiple','Ticket_Frequency']]= scale.fit_transform(train_inputs[['Age','SibSp','Parch','Fare','cabin_multiple','Ticket_Frequency']])\n",
    "train_inputs[['SibSp','Parch','Fare','cabin_multiple','Ticket_Frequency']]= scale.fit_transform(train_inputs[['SibSp','Parch','Fare','cabin_multiple','Ticket_Frequency']])\n",
    "scaled_training_inputs = train_inputs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = train_csv['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv[['SibSp','Parch','Fare','cabin_multiple','Ticket_Frequency']]= scale.fit_transform(test_csv[['SibSp','Parch','Fare','cabin_multiple','Ticket_Frequency']])\n",
    "#test_csv[['Age','SibSp','Parch','Fare','cabin_multiple','Ticket_Frequency']]= scale.fit_transform(test_csv[['Age','SibSp','Parch','Fare','cabin_multiple','Ticket_Frequency']])\n",
    "X_test_scaled = test_csv.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train csv data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# declare 4 variables for the split\n",
    "x_train, x_test, y_train, y_test = train_test_split(scaled_training_inputs, targets, #train_size = 0.8, \n",
    "                                                                            test_size = 0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81944444 0.81690141 0.8028169  0.81690141 0.88732394 0.83098592\n",
      " 0.78873239 0.81690141 0.78873239 0.81690141]\n",
      "0.8185641627543037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "lr2 = LogisticRegression()\n",
    "cv = cross_val_score(lr2,x_train,y_train,cv=10)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76388889 0.8028169  0.76056338 0.78873239 0.87323944 0.81690141\n",
      " 0.8028169  0.77464789 0.78873239 0.85915493]\n",
      "0.8031494522691706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state = 1,min_samples_split=5)\n",
    "cv = cross_val_score(rf,x_train,y_train,cv=10)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:14:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:14:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8214788732394366\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier(random_state =1,learning_rate =0.2,use_label_encoder=False)\n",
    "cv = cross_val_score(xgb,x_train,y_train,cv=10, verbose=0)\n",
    "#print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:14:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-logloss:0.60064\n",
      "[1]\tvalidation_0-logloss:0.54381\n",
      "[2]\tvalidation_0-logloss:0.50453\n",
      "[3]\tvalidation_0-logloss:0.47662\n",
      "[4]\tvalidation_0-logloss:0.45744\n",
      "[5]\tvalidation_0-logloss:0.44434\n",
      "[6]\tvalidation_0-logloss:0.43762\n",
      "[7]\tvalidation_0-logloss:0.42924\n",
      "[8]\tvalidation_0-logloss:0.42690\n",
      "[9]\tvalidation_0-logloss:0.42547\n",
      "[10]\tvalidation_0-logloss:0.42480\n",
      "[11]\tvalidation_0-logloss:0.42559\n",
      "[12]\tvalidation_0-logloss:0.42530\n",
      "[13]\tvalidation_0-logloss:0.42567\n",
      "[14]\tvalidation_0-logloss:0.42370\n",
      "[15]\tvalidation_0-logloss:0.42495\n",
      "[16]\tvalidation_0-logloss:0.42524\n",
      "[17]\tvalidation_0-logloss:0.42532\n",
      "[18]\tvalidation_0-logloss:0.42453\n",
      "[19]\tvalidation_0-logloss:0.42290\n",
      "[20]\tvalidation_0-logloss:0.42141\n",
      "[21]\tvalidation_0-logloss:0.42537\n",
      "[22]\tvalidation_0-logloss:0.42279\n",
      "[23]\tvalidation_0-logloss:0.42489\n",
      "[24]\tvalidation_0-logloss:0.42562\n",
      "[25]\tvalidation_0-logloss:0.42380\n",
      "[26]\tvalidation_0-logloss:0.42731\n",
      "[27]\tvalidation_0-logloss:0.42753\n",
      "[28]\tvalidation_0-logloss:0.43037\n",
      "[29]\tvalidation_0-logloss:0.43277\n",
      "[30]\tvalidation_0-logloss:0.43694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8314606741573034"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_set = [(x_test, y_test)]\n",
    "xgb.fit(x_train, y_train, eval_set=eval_set, early_stopping_rounds=10)\n",
    "xgb.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictions = xgb.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_xgb = pd.DataFrame({\n",
    "        \"PassengerId\": raw_data_test['PassengerId'],\n",
    "       \"Survived\": xgb_predictions\n",
    "  })\n",
    "submission_xgb.to_csv('xgb_predictions_sumission7Feb.csv',  index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
